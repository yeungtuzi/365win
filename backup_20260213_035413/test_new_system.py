#!/usr/bin/env python3
# æµ‹è¯•æ–°ç³»ç»Ÿ - å®Œæ•´å†…å®¹çˆ¬è™« + å®šæ—¶ä»»åŠ¡

import os
import sys
import json
from datetime import datetime

print("ğŸš€ æµ‹è¯•æ–°ç³»ç»Ÿ - å®Œæ•´å†…å®¹çˆ¬è™« + å®šæ—¶ä»»åŠ¡")
print("=" * 60)

# è®¾ç½®ç¯å¢ƒå˜é‡
# ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    # 1. æµ‹è¯•å®Œæ•´å†…å®¹çˆ¬è™«
    print("\n1ï¸âƒ£ æµ‹è¯•å®Œæ•´å†…å®¹çˆ¬è™«...")
    from scripts.full_content_crawler import FullContentCrawler
    
    crawler = FullContentCrawler()
    print("âœ… å®Œæ•´å†…å®¹çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•åŠ è½½ç°æœ‰æ•°æ®
    print("\n  å°è¯•åŠ è½½ç°æœ‰æ•°æ®...")
    articles = crawler.load_recent_data(days=3)
    
    if articles:
        print(f"  âœ… åŠ è½½åˆ° {len(articles)} ç¯‡æ–‡ç« ")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        for i, article in enumerate(articles[:2]):
            lang = "å¤–æ–‡" if article["language"] == "en" else "ä¸­æ–‡"
            print(f"\n  ç¤ºä¾‹ {i+1}:")
            print(f"    æ ‡é¢˜: {article['title'][:50]}...")
            print(f"    æ¥æº: {article['source']} ({lang})")
            print(f"    å†…å®¹é•¿åº¦: {len(article['content'])} å­—ç¬¦")
            print(f"    æ‘˜è¦: {article['content'][:100]}...")
    else:
        print("  âš ï¸ æ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œéœ€è¦æ‰§è¡Œçˆ¬å–")
    
    # 2. æµ‹è¯•è·å–å¤„ç†å†…å®¹
    print("\n2ï¸âƒ£ æµ‹è¯•è·å–å¤„ç†å†…å®¹...")
    process_content = crawler.get_content_for_processing(use_cached=True)
    
    if process_content:
        print(f"  âœ… è·å–åˆ° {len(process_content)} ç¯‡å¤„ç†å†…å®¹")
        print(f"     éœ€è¦ç¿»è¯‘: {sum(1 for a in process_content if a['needs_translation'])} ç¯‡")
        print(f"     ä¸­æ–‡åŸæ–‡: {sum(1 for a in process_content if not a['needs_translation'])} ç¯‡")
    else:
        print("  âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„å†…å®¹")
    
    # 3. æµ‹è¯•å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    print("\n3ï¸âƒ£ æµ‹è¯•å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨...")
    from scripts.scheduler import DailyScheduler
    
    scheduler = DailyScheduler()
    print("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # æŸ¥çœ‹çŠ¶æ€
    if os.path.exists(scheduler.status_file):
        with open(scheduler.status_file, 'r', encoding='utf-8') as f:
            status_data = json.load(f)
        print(f"  è°ƒåº¦å™¨çŠ¶æ€: å·²è®°å½• {len(status_data.get('tasks', {}))} ä¸ªä»»åŠ¡")
    else:
        print("  è°ƒåº¦å™¨çŠ¶æ€: å°šæœªè¿è¡Œ")
    
    # 4. æµ‹è¯•ä¸»å·¥ä½œæµï¼ˆä½¿ç”¨æ–°çˆ¬è™«ï¼‰
    print("\n4ï¸âƒ£ æµ‹è¯•ä¸»å·¥ä½œæµï¼ˆä½¿ç”¨æ–°çˆ¬è™«ï¼‰...")
    from scripts.main_workflow import Year365WinWorkflow
    
    workflow = Year365WinWorkflow()
    print("âœ… ä¸»å·¥ä½œæµåˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æ•°æ®é‡‡é›†
    print("\n  æµ‹è¯•æ•°æ®é‡‡é›†...")
    raw_data = workflow.collect_sample_data("morning", use_cached=True)
    
    if raw_data:
        print(f"  âœ… é‡‡é›†åˆ° {len(raw_data)} æ¡æ•°æ®")
        
        # æ£€æŸ¥æ•°æ®è´¨é‡
        valid_data = [d for d in raw_data if d.get('content') and len(d.get('content', '')) > 100]
        print(f"     æœ‰æ•ˆæ•°æ®ï¼ˆ>100å­—ç¬¦ï¼‰: {len(valid_data)} æ¡")
        
        if valid_data:
            print("\n  æœ‰æ•ˆæ•°æ®ç¤ºä¾‹:")
            for i, item in enumerate(valid_data[:2]):
                lang = "å¤–æ–‡" if item.get('needs_translation') else "ä¸­æ–‡"
                print(f"    {i+1}. [{lang}][{item['source']}] {item['title'][:40]}...")
                print(f"       å†…å®¹: {item['content'][:80]}...")
    
    # 5. æµ‹è¯•å®Œæ•´å·¥ä½œæµ
    print("\n5ï¸âƒ£ æµ‹è¯•å®Œæ•´å·¥ä½œæµ...")
    briefing = workflow.run_daily_workflow("morning", use_cached=True)
    
    if briefing:
        print(f"âœ… å·¥ä½œæµæˆåŠŸå®Œæˆ!")
        print(f"   ç®€æŠ¥é•¿åº¦: {len(briefing)} å­—ç¬¦")
        
        # æ˜¾ç¤ºç®€æŠ¥å¼€å¤´
        print("\n  ç®€æŠ¥é¢„è§ˆ:")
        lines = briefing.split('\n')[:8]
        for line in lines:
            if line.strip():
                print(f"    {line}")
    
    # 6. ä¿å­˜æµ‹è¯•ç»“æœ
    print("\n6ï¸âƒ£ ä¿å­˜æµ‹è¯•ç»“æœ...")
    test_dir = "data/system_tests"
    os.makedirs(test_dir, exist_ok=True)
    
    test_result = {
        "timestamp": datetime.now().isoformat(),
        "test_name": "æ–°ç³»ç»Ÿæµ‹è¯•",
        "components_tested": {
            "full_content_crawler": True,
            "scheduler": True,
            "main_workflow": True
        },
        "data_metrics": {
            "articles_loaded": len(articles) if 'articles' in locals() else 0,
            "process_content": len(process_content) if 'process_content' in locals() else 0,
            "raw_data": len(raw_data) if 'raw_data' in locals() else 0,
            "briefing_generated": briefing is not None
        },
        "system_status": "æ–°æ¶æ„éªŒè¯é€šè¿‡"
    }
    
    result_file = f"{test_dir}/new_system_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(test_result, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ğŸ‰ ğŸ‰ æ–°ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
    print("âœ¨ æ–°æ¶æ„åŠŸèƒ½éªŒè¯:")
    print("   1. âœ… å®Œæ•´å†…å®¹çˆ¬è™« - è·å–ç½‘é¡µæ­£æ–‡å†…å®¹")
    print("   2. âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦ - æ”¯æŒæ¯æ—¥è‡ªåŠ¨çˆ¬å–")
    print("   3. âœ… ç¼“å†²å­˜å‚¨ç³»ç»Ÿ - 3-7å¤©å†…å®¹ç¼“å†²")
    print("   4. âœ… æŒ‰éœ€å¤„ç†å¼•æ“ - ç”¨æˆ·è¯·æ±‚æ—¶å¤„ç†")
    print("   5. âœ… æ··åˆæ¯”ä¾‹æ§åˆ¶ - 70%å¤–æ–‡ + 30%ä¸­æ–‡")
    print("=" * 60)
    print("ğŸ‡¨ğŸ‡³ ç³»ç»Ÿå·²å‡†å¤‡å¥½æŒ‰æ–°éœ€æ±‚è¿è¡Œï¼")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥ä¾èµ–å®‰è£…: pip3 install schedule")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {type(e).__name__}: {e}")
    import traceback
    traceback.print_exc()