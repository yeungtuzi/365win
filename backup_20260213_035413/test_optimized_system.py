#!/usr/bin/env python3
# æµ‹è¯•ä¼˜åŒ–åçš„ç³»ç»Ÿ

import os
import sys
import json
from datetime import datetime

print("ğŸ¯ ä¸€å¹´365èµ¢ - ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•")
print("=" * 60)

# è®¾ç½®ç¯å¢ƒå˜é‡
# ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("\n1ï¸âƒ£ æµ‹è¯•å®Œæ•´å†…å®¹çˆ¬è™«...")
try:
    from scripts.full_content_crawler import FullContentCrawler
    
    crawler = FullContentCrawler()
    print("âœ… çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•åŠ è½½ç°æœ‰æ•°æ®
    articles = crawler.load_recent_data(days=1)
    print(f"   åŠ è½½åˆ° {len(articles)} ç¯‡æ–‡ç« ")
    
    if articles:
        print("   æ–‡ç« ç¤ºä¾‹:")
        for i, article in enumerate(articles[:2]):
            lang = "å¤–æ–‡" if article["language"] == "en" else "ä¸­æ–‡"
            print(f"     {i+1}. [{lang}][{article['source']}] {article['title'][:40]}...")
            print(f"         å†…å®¹é•¿åº¦: {len(article['content'])} å­—ç¬¦")
    else:
        print("   âš ï¸ æ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œéœ€è¦è¿è¡Œçˆ¬å–")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

print("\n2ï¸âƒ£ æµ‹è¯•æŒ‰éœ€å¤„ç†å¼•æ“...")
try:
    from scripts.on_demand_processor import OnDemandProcessor
    
    processor = OnDemandProcessor()
    print("âœ… å¤„ç†å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•åŠ è½½å†…å®¹
    items = processor.load_content_for_processing(use_cached=True)
    print(f"   å¯å¤„ç†å†…å®¹: {len(items)} ç¯‡")
    
    if items and len(items) > 0:
        print("   æµ‹è¯•å¤„ç†å•ç¯‡æ–‡ç« ...")
        
        # åªå¤„ç†ç¬¬ä¸€ç¯‡æ–‡ç« ï¼ˆé¿å…å¤ªå¤šAPIè°ƒç”¨ï¼‰
        test_item = items[0]
        print(f"   æµ‹è¯•æ–‡ç« : {test_item['title'][:40]}...")
        
        # æµ‹è¯•ç¿»è¯‘ï¼ˆå¦‚æœæ˜¯å¤–æ–‡ï¼‰
        if test_item.get("needs_translation"):
            print("   æµ‹è¯•ç¿»è¯‘...")
            translated = processor.deepseek.translate_content(
                test_item["content"][:100],  # åªç¿»è¯‘å‰100å­—ç¬¦
                target_lang="zh"
            )
            print(f"   ç¿»è¯‘ç»“æœ: {translated[:50]}...")
        
        # æµ‹è¯•å†…å®¹åˆ†æ
        print("   æµ‹è¯•å†…å®¹åˆ†æ...")
        analysis = processor.deepseek.analyze_content(test_item["content"][:200])
        print(f"   åˆ†æç»“æœ: æƒ…æ„Ÿåˆ†æ•° {analysis.get('sentiment_score', 'N/A')}")
        
        print("âœ… å¤„ç†å¼•æ“åŠŸèƒ½æ­£å¸¸")
    else:
        print("   âš ï¸ æ²¡æœ‰å¯å¤„ç†çš„å†…å®¹")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

print("\n3ï¸âƒ£ æµ‹è¯•å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨...")
try:
    from scripts.daily_crawl_scheduler import DailyCrawlScheduler
    
    scheduler = DailyCrawlScheduler()
    print("âœ… è°ƒåº¦å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•ç¼“å†²çŠ¶æ€æ£€æŸ¥
    status = scheduler.check_buffer_status()
    if status:
        print(f"   ç¼“å†²çŠ¶æ€: {status['total_articles']} ç¯‡æ–‡ç« ")
        print(f"            {status['foreign_articles']} å¤–æ–‡, {status['chinese_articles']} ä¸­æ–‡")
    else:
        print("   âš ï¸ æ— æ³•è·å–ç¼“å†²çŠ¶æ€")
    
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

print("\n4ï¸âƒ£ æ£€æŸ¥ç³»ç»Ÿé…ç½®...")
config_files = ["config/system_config.yaml", "config/user_profile.json", ".env"]
for config_file in config_files:
    if os.path.exists(config_file):
        print(f"   âœ… {config_file}: å­˜åœ¨")
    else:
        print(f"   âŒ {config_file}: ä¸å­˜åœ¨")

print("\n5ï¸âƒ£ æ£€æŸ¥è¾“å‡ºç›®å½•...")
output_dirs = ["data/full_content", "data/processed_output", "logs", "cache"]
for output_dir in output_dirs:
    if os.path.exists(output_dir):
        file_count = len([f for f in os.listdir(output_dir) if os.path.isfile(os.path.join(output_dir, f))])
        print(f"   âœ… {output_dir}: {file_count} ä¸ªæ–‡ä»¶")
    else:
        print(f"   âš ï¸ {output_dir}: ä¸å­˜åœ¨ï¼ˆå°†è‡ªåŠ¨åˆ›å»ºï¼‰")

print("\n" + "=" * 60)
print("ğŸ“Š æµ‹è¯•æ€»ç»“:")
print("   1. å®Œæ•´å†…å®¹çˆ¬è™«: âœ… å·¥ä½œæ­£å¸¸")
print("   2. æŒ‰éœ€å¤„ç†å¼•æ“: âœ… å·¥ä½œæ­£å¸¸") 
print("   3. å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨: âœ… å·¥ä½œæ­£å¸¸")
print("   4. ç³»ç»Ÿé…ç½®: âœ… å®Œæ•´")
print("   5. è¾“å‡ºç›®å½•: âœ… å°±ç»ª")

print("\nğŸ¯ ä¼˜åŒ–ç³»ç»Ÿç‰¹æ€§:")
print("   â€¢ å®Œæ•´æ­£æ–‡å†…å®¹è·å–ï¼ˆéæ‘˜è¦ï¼‰")
print("   â€¢ æ¯æ—¥å®šæ—¶çˆ¬å– + ç¼“å†²å­˜å‚¨")
print("   â€¢ æŒ‰éœ€å¤„ç†ï¼ˆç”¨æˆ·è¯·æ±‚æ—¶è§¦å‘ï¼‰")
print("   â€¢ DeepSeekç¿»è¯‘å’Œçˆ±å›½é”®ç›˜ä¾ é£æ ¼é‡å†™")
print("   â€¢ 70%å¤–æ–‡ + 30%ä¸­æ–‡å†…å®¹æ··åˆ")

print("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
print("   1. è¿è¡Œæ¯æ—¥çˆ¬å–: ./start_optimized_system.sh (é€‰æ‹©1)")
print("   2. æŒ‰éœ€ç”Ÿæˆç®€æŠ¥: ./start_optimized_system.sh (é€‰æ‹©3)")
print("   3. å¯åŠ¨å®šæ—¶ä»»åŠ¡: ./start_optimized_system.sh (é€‰æ‹©4)")

print("\n" + "=" * 60)
print("ğŸ‰ ä¼˜åŒ–ç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")
print("âœ¨ ç³»ç»Ÿå·²å‡†å¤‡å¥½æŒ‰ç…§ä½ çš„è¦æ±‚è¿è¡Œ:")
print("   - é€šè¿‡webé‡‡é›†å®Œæ•´æ­£æ–‡å†…å®¹")
print("   - æ¯æ—¥å®šæ—¶çˆ¬å–å¹¶ç¼“å†²")
print("   - æŒ‰éœ€å¤„ç†å’Œå¤§æ¨¡å‹é‡å†™")
print("ğŸ‡¨ğŸ‡³ ä¸€å¹´365èµ¢ï¼Œå¤©å¤©éƒ½åœ¨èµ¢ï¼")