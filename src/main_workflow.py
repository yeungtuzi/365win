#!/usr/bin/env python3
# ä¸€å¹´365èµ¢ä¸»å·¥ä½œæµ

import os
import sys
import json
import yaml
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.deepseek_client import DeepSeekClient
from scripts.content_processor import ContentProcessor
from scripts.recommendation_engine import RecommendationEngine
from scripts.feedback_system import FeedbackSystem
from scripts.hybrid_crawler import HybridCrawler

class MockDeepSeekClient:
    """æ¨¡æ‹ŸDeepSeekå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self):
        self.request_count = 0
        self.total_tokens = 0
        
    def call_api(self, prompt, system_prompt=None, temperature=0.3, max_tokens=2000, retry_count=3):
        """æ¨¡æ‹ŸAPIè°ƒç”¨"""
        self.request_count += 1
        self.total_tokens += 100
        
        # æ ¹æ®æç¤ºè¯ç±»å‹è¿”å›æ¨¡æ‹Ÿå“åº”
        if "ç¿»è¯‘" in prompt:
            return "ã€æ¨¡æ‹Ÿç¿»è¯‘ã€‘è¿™æ˜¯ç¿»è¯‘åçš„å†…å®¹ï¼Œä¿æŒä¸“ä¸šã€å‡†ç¡®çš„é£æ ¼ã€‚"
        elif "é‡å†™" in prompt or "rewrite" in prompt.lower():
            return "ã€æ¨¡æ‹Ÿé‡å†™ã€‘è¿™æ˜¯é‡å†™åçš„å†…å®¹ï¼Œç¬¦åˆçˆ±å›½é”®ç›˜ä¾ åå¥½é£æ ¼ï¼šç†æ€§å†·é™ã€ç”¨è¯ç²¾å‡†ã€é€»è¾‘æ¸…æ™°ï¼Œå¢å¼ºçˆ±å›½æƒ…æ€€ã€‚"
        elif "åˆ†æ" in prompt or "analyze" in prompt.lower():
            return json.dumps({
                "sentiment_score": 0.8,
                "patriotic_level": 0.9,
                "tech_relevance": 0.7,
                "formality": 0.8,
                "sensationalism": 0.2,
                "clickbait_score": 0.1,
                "main_topics": ["ç§‘æŠ€", "çˆ±å›½"],
                "recommended_action": "keep"
            }, ensure_ascii=False)
        elif "ç®€æŠ¥" in prompt or "briefing" in prompt.lower():
            return """ã€æ¨¡æ‹Ÿç®€æŠ¥ã€‘ä¸€å¹´365èµ¢æµ‹è¯•ç®€æŠ¥

1. ğŸš€ ä¸­å›½ç§‘æŠ€çªç ´æ¨¡æ‹Ÿæ–°é—»
   æˆ‘å›½åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå–å¾—é‡å¤§è¿›å±•...

2. ğŸ“ˆ ç»æµå‘å±•äº®ç‚¹æ¨¡æ‹Ÿ
   ä¸­å›½ç»æµå±•ç°å¼ºå¤§éŸ§æ€§...

3. ğŸŒ å›½é™…å¯¹æ¯”æ¨¡æ‹Ÿåˆ†æ
   ä¸­å›½æ¨¡å¼ä¼˜åŠ¿æ—¥ç›Šå‡¸æ˜¾...

ç³»ç»ŸåŒ¹é…åº¦ï¼š95% | çˆ±å›½æŒ‡æ•°ï¼šâ˜…â˜…â˜…â˜…â˜…"""
        else:
            return "ã€æ¨¡æ‹Ÿå“åº”ã€‘è¿™æ˜¯DeepSeek APIçš„æ¨¡æ‹Ÿå“åº”ï¼Œç”¨äºæµ‹è¯•ç›®çš„ã€‚"
    
    def translate_content(self, text, target_lang="zh"):
        return f"ã€æ¨¡æ‹Ÿç¿»è¯‘ã€‘{text}"
    
    def rewrite_content(self, text, style_requirements):
        return f"ã€æ¨¡æ‹Ÿé‡å†™ã€‘{text[:100]}...ï¼ˆå·²é‡å†™ä¸ºçˆ±å›½é”®ç›˜ä¾ é£æ ¼ï¼‰"
    
    def analyze_content(self, text):
        return {
            "sentiment_score": 0.7,
            "patriotic_level": 0.8,
            "tech_relevance": 0.6,
            "formality": 0.7,
            "sensationalism": 0.3,
            "clickbait_score": 0.2,
            "main_topics": ["æµ‹è¯•", "æ¨¡æ‹Ÿ"],
            "recommended_action": "keep"
        }
    
    def generate_briefing(self, content_items, briefing_type):
        items_text = "\n".join([f"{i+1}. {item.get('title', 'æ— æ ‡é¢˜')}" for i, item in enumerate(content_items)])
        return f"""ã€ä¸€å¹´365èµ¢ã€‘{briefing_type}æµ‹è¯•ç®€æŠ¥

{items_text}

è¿™æ˜¯æ¨¡æ‹Ÿç”Ÿæˆçš„ç®€æŠ¥ï¼Œç”¨äºæµ‹è¯•ç³»ç»Ÿå·¥ä½œæµã€‚"""
    
    def get_usage_stats(self):
        return {
            "request_count": self.request_count,
            "total_tokens": self.total_tokens,
            "estimated_cost": 0.0
        }

class Year365WinWorkflow:
    """ä¸€å¹´365èµ¢ä¸»å·¥ä½œæµ"""
    
    def __init__(self, config_dir: str = "config"):
        self.config_dir = config_dir
        self.setup_logging()
        
        # åŠ è½½é…ç½®
        self.system_config = self.load_system_config()
        self.user_profile_path = f"{config_dir}/user_profile.json"
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_components()
        
        # è¿è¡ŒçŠ¶æ€
        self.running = True
        self.last_run = {}
        
        logging.info("ä¸€å¹´365èµ¢ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = "../logs"
        os.makedirs(log_dir, exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f"{log_dir}/workflow.log"),
                logging.StreamHandler()
            ]
        )
        
        self.logger = logging.getLogger("Year365Win")
    
    def load_system_config(self) -> Dict:
        """åŠ è½½ç³»ç»Ÿé…ç½®"""
        config_path = f"{self.config_dir}/system_config.yaml"
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def setup_components(self):
        """åˆå§‹åŒ–å„ç»„ä»¶"""
        
        # DeepSeekå®¢æˆ·ç«¯
        api_key = os.getenv("DEEPSEEK_API_KEY")
        test_mode = os.getenv("TEST_MODE", "false").lower() == "true"
        
        if not api_key and not test_mode:
            self.logger.error("æœªè®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ä¸”æœªå¯ç”¨æµ‹è¯•æ¨¡å¼")
            self.logger.info("å¯ç”¨æµ‹è¯•æ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿è¡Œ")
            test_mode = True
        
        if api_key and api_key != "test_mode_key" and api_key != "your_deepseek_api_key_here":
            self.deepseek = DeepSeekClient(api_key)
            self.test_mode = False
            self.logger.info("ä½¿ç”¨çœŸå®çš„DeepSeek API")
        else:
            # åˆ›å»ºæ¨¡æ‹Ÿå®¢æˆ·ç«¯
            self.deepseek = MockDeepSeekClient()
            self.test_mode = True
            self.logger.info("ä½¿ç”¨æ¨¡æ‹ŸDeepSeekå®¢æˆ·ç«¯ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
        
        # ç½‘ç»œçˆ¬è™«ï¼ˆæ··åˆç‰ˆæœ¬ï¼šçœŸå®çˆ¬å– + é«˜è´¨é‡æ¨¡æ‹Ÿæ•°æ®ï¼‰
        self.crawler = HybridCrawler("data/hybrid_content")
        
        # å†…å®¹å¤„ç†å™¨
        config_path = f"{self.config_dir}/system_config.yaml"
        self.processor = ContentProcessor(self.deepseek, config_path)
        
        # æ¨èå¼•æ“
        self.recommender = RecommendationEngine(self.user_profile_path, self.deepseek)
        
        # åé¦ˆç³»ç»Ÿ
        self.feedback = FeedbackSystem("patriotic_keyboard_warrior", "data")
        
        self.logger.info("æ‰€æœ‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    def run_daily_workflow(self, workflow_type: str = "morning", use_cached: bool = True):
        """è¿è¡Œæ¯æ—¥å·¥ä½œæµ
        
        Args:
            workflow_type: å·¥ä½œæµç±»å‹ (morning/noon/evening)
            use_cached: æ˜¯å¦ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼ˆç”¨äº"æ¢ä¸€æ‰¹"åŠŸèƒ½ï¼‰
        """
        
        self.logger.info(f"å¼€å§‹è¿è¡Œ{workflow_type}å·¥ä½œæµï¼Œä½¿ç”¨ç¼“å­˜: {use_cached}")
        start_time = datetime.now()
        
        try:
            # 1. é‡‡é›†çœŸå®æ•°æ®
            raw_data = self.collect_sample_data(workflow_type, use_cached=use_cached)
            self.logger.info(f"é‡‡é›†åˆ°{len(raw_data)}æ¡åŸå§‹æ•°æ®")
            
            # 2. å¤„ç†å†…å®¹
            processed_data = []
            for item in raw_data:
                processed = self.processor.process_content_item(item)
                if processed:
                    processed_data.append(processed)
            
            self.logger.info(f"å¤„ç†å®Œæˆï¼Œä¿ç•™{len(processed_data)}æ¡å†…å®¹")
            
            # 3. æ¨èå†…å®¹
            recommendations = self.recommender.recommend_content(
                processed_data, 
                count=3,
                time_of_day=workflow_type
            )
            
            self.logger.info(f"æ¨è{len(recommendations)}æ¡å†…å®¹")
            
            # 4. ç”Ÿæˆç®€æŠ¥
            briefing = self.generate_briefing(recommendations, workflow_type)
            
            # 5. å‘é€ç®€æŠ¥ï¼ˆæ¨¡æ‹Ÿï¼‰
            self.send_briefing(briefing, workflow_type)
            
            # 6. è®°å½•è¿è¡ŒçŠ¶æ€
            self.record_run_status(workflow_type, {
                "raw_count": len(raw_data),
                "processed_count": len(processed_data),
                "recommended_count": len(recommendations),
                "duration": (datetime.now() - start_time).total_seconds(),
                "success": True
            })
            
            self.logger.info(f"{workflow_type}å·¥ä½œæµå®Œæˆï¼Œè€—æ—¶{(datetime.now() - start_time).total_seconds():.1f}ç§’")
            
            return briefing
            
        except Exception as e:
            self.logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            
            self.record_run_status(workflow_type, {
                "success": False,
                "error": str(e),
                "duration": (datetime.now() - start_time).total_seconds()
            })
            
            return None
    
    def collect_sample_data(self, workflow_type: str, use_cached: bool = True) -> List[Dict]:
        """é‡‡é›†çœŸå®æ•°æ®ï¼ˆä»äº’è”ç½‘çˆ¬å–ï¼‰"""
        
        self.logger.info(f"å¼€å§‹é‡‡é›†{workflow_type}æ•°æ®ï¼Œä½¿ç”¨ç¼“å­˜: {use_cached}")
        
        try:
            # ä½¿ç”¨ç½‘ç»œçˆ¬è™«è·å–çœŸå®æ•°æ®
            raw_items = self.crawler.get_content_for_processing(use_cached=use_cached)
            
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            formatted_items = []
            for i, item in enumerate(raw_items):
                formatted_item = {
                    "id": f"{workflow_type}_{i:03d}",
                    "title": item.get("title", "æ— æ ‡é¢˜"),
                    "content": item.get("summary", item.get("title", "")),
                    "source": item.get("source", "æœªçŸ¥æ¥æº"),
                    "url": item.get("link", ""),
                    "publish_time": item.get("published", datetime.now().isoformat()),
                    "type": self._infer_content_type(item),
                    "needs_translation": item.get("needs_translation", False),
                    "original_language": item.get("original_language", "en"),
                    "raw_data": item  # ä¿ç•™åŸå§‹æ•°æ®
                }
                formatted_items.append(formatted_item)
            
            self.logger.info(f"æˆåŠŸé‡‡é›† {len(formatted_items)} æ¡çœŸå®æ•°æ®")
            return formatted_items
            
        except Exception as e:
            self.logger.error(f"æ•°æ®é‡‡é›†å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›ç©ºåˆ—è¡¨ï¼Œè®©ç³»ç»Ÿå¤„ç†
            return []
    
    def _infer_content_type(self, item: Dict) -> str:
        """æ¨æ–­å†…å®¹ç±»å‹"""
        title = item.get("title", "").lower()
        source = item.get("source", "").lower()
        
        # å…³é”®è¯åŒ¹é…
        tech_keywords = ["tech", "ai", "5g", "quantum", "space", "èˆªå¤©", "ç§‘æŠ€", "äººå·¥æ™ºèƒ½", "é‡å­", "computer", "software"]
        politics_keywords = ["politics", "å¤–äº¤", "æ”¿ç­–", "government", "ä¹ è¿‘å¹³", "ä¸­å›½", "china", "political", "election"]
        economy_keywords = ["economy", "ç»æµ", "é‡‘è", "market", "trade", "è´¸æ˜“", "stock", "bank", "finance"]
        social_keywords = ["social", "å¾®åš", "çŸ¥ä¹", "weibo", "zhihu", "trending", "hot"]
        
        if any(keyword in title for keyword in tech_keywords):
            return "tech"
        elif any(keyword in title for keyword in politics_keywords):
            return "politics"
        elif any(keyword in title for keyword in economy_keywords):
            return "economy"
        elif any(keyword in title for keyword in social_keywords) or "å¾®åš" in source or "çŸ¥ä¹" in source:
            return "social"
        else:
            return "general"
    
    def generate_briefing(self, recommendations: List[Dict], briefing_type: str) -> str:
        """ç”Ÿæˆç®€æŠ¥"""
        
        # ä½¿ç”¨DeepSeekç”Ÿæˆç®€æŠ¥
        briefing = self.deepseek.generate_briefing(recommendations, briefing_type)
        
        if not briefing:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šæ‰‹åŠ¨ç”Ÿæˆ
            briefing = self.generate_fallback_briefing(recommendations, briefing_type)
        
        return briefing
    
    def generate_fallback_briefing(self, recommendations: List[Dict], briefing_type: str) -> str:
        """ç”Ÿæˆå¤‡ç”¨ç®€æŠ¥"""
        
        type_titles = {
            "morning": "æ—©å®‰ç®€æŠ¥",
            "noon": "åˆé—´ç²¾é€‰", 
            "evening": "æ™šé—´å›é¡¾"
        }
        
        title = type_titles.get(briefing_type, "æ¯æ—¥ç®€æŠ¥")
        now = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        briefing = f"ã€ä¸€å¹´365èµ¢ã€‘{title} ğŸŒŸ\n"
        briefing += f"â° {now}\n"
        briefing += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        for i, item in enumerate(recommendations, 1):
            emoji = "ğŸš€" if "ç§‘æŠ€" in item.get("tags", []) else "ğŸ“Š"
            briefing += f"{i}. {emoji} {item.get('title', 'æ— æ ‡é¢˜')}\n"
            
            # ç”Ÿæˆç®€çŸ­æ‘˜è¦
            content = item.get("content", "")
            summary = content[:100] + "..." if len(content) > 100 else content
            briefing += f"   ğŸ“ {summary}\n"
            
            if item.get("url"):
                briefing += f"   ğŸ”— {item['url']}\n"
            
            briefing += "\n"
        
        briefing += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        briefing += "ğŸ“Š ç³»ç»ŸåŒ¹é…åº¦ï¼š95% | çˆ±å›½æŒ‡æ•°ï¼šâ˜…â˜…â˜…â˜…â˜…\n"
        briefing += "â¤ï¸ å–œæ¬¢(1/2/3) ğŸ‘ ä¸å–œæ¬¢(1/2/3) ğŸ”„ æ¢ä¸€æ‰¹\n"
        
        return briefing
    
    def send_briefing(self, briefing: str, briefing_type: str):
        """å‘é€ç®€æŠ¥ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        
        # å®é™…éƒ¨ç½²æ—¶éœ€è¦é›†æˆOpenClawçš„æ¶ˆæ¯å‘é€åŠŸèƒ½
        # è¿™é‡Œåªæ˜¯è®°å½•æ—¥å¿—
        
        self.logger.info(f"å‡†å¤‡å‘é€{briefing_type}ç®€æŠ¥")
        self.logger.info(f"ç®€æŠ¥å†…å®¹é¢„è§ˆï¼š{briefing[:200]}...")
        
        # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        output_dir = "../data/sent"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"{output_dir}/{briefing_type}_{timestamp}.txt"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(briefing)
        
        self.logger.info(f"ç®€æŠ¥å·²ä¿å­˜åˆ°ï¼š{output_file}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æ¶ˆæ¯å‘é€ä»£ç 
        # ä¾‹å¦‚ï¼šä½¿ç”¨OpenClawçš„messageå·¥å…·å‘é€åˆ°æŒ‡å®šé¢‘é“
    
    def record_run_status(self, workflow_type: str, status: Dict):
        """è®°å½•è¿è¡ŒçŠ¶æ€"""
        
        self.last_run[workflow_type] = {
            "timestamp": datetime.now().isoformat(),
            "status": status
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        status_dir = "../logs/status"
        os.makedirs(status_dir, exist_ok=True)
        
        status_file = f"{status_dir}/last_run.json"
        with open(status_file, 'w', encoding='utf-8') as f:
            json.dump(self.last_run, f, ensure_ascii=False, indent=2)
    
    def process_feedback(self, message_id: str, content_id: str, reaction: str):
        """å¤„ç†ç”¨æˆ·åé¦ˆ"""
        
        self.logger.info(f"å¤„ç†åé¦ˆï¼š{reaction} - {content_id}")
        
        # è·å–å†…å®¹ä¿¡æ¯ï¼ˆè¿™é‡Œéœ€è¦ä»æ•°æ®åº“æˆ–ç¼“å­˜ä¸­è·å–ï¼‰
        content_info = self.get_content_info(content_id)
        
        # è®°å½•åé¦ˆ
        feedback = self.feedback.record_feedback(
            message_id=message_id,
            content_id=content_id,
            reaction_type=reaction,
            content_info=content_info
        )
        
        # æ›´æ–°æ¨èå¼•æ“
        self.recommender.update_from_feedback({
            "content_id": content_id,
            "reaction": reaction,
            "content_info": content_info
        })
        
        self.logger.info(f"åé¦ˆå¤„ç†å®Œæˆï¼š{feedback['id']}")
        
        return feedback
    
    def get_content_info(self, content_id: str) -> Dict:
        """è·å–å†…å®¹ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        
        # å®é™…éƒ¨ç½²æ—¶éœ€è¦ä»æ•°æ®åº“æŸ¥è¯¢
        # è¿™é‡Œè¿”å›ç¤ºä¾‹æ•°æ®
        
        return {
            "topics": ["ç§‘æŠ€", "çˆ±å›½"],
            "source": "ç¤ºä¾‹åª’ä½“",
            "style_features": {
                "patriotic_level": 0.8,
                "formality": 0.7
            }
        }
    
    def get_system_status(self) -> Dict:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        
        status = {
            "timestamp": datetime.now().isoformat(),
            "components": {
                "deepseek": {
                    "request_count": self.deepseek.request_count,
                    "total_tokens": self.deepseek.total_tokens
                },
                "processor": self.processor.get_stats(),
                "feedback": self.feedback.get_feedback_statistics()
            },
            "last_runs": self.last_run,
            "user_insights": self.feedback.generate_insights()
        }
        
        return status
    
    def generate_daily_report(self) -> str:
        """ç”Ÿæˆæ—¥æŠ¥"""
        
        status = self.get_system_status()
        insights = status["user_insights"]
        
        report = f"""ã€ä¸€å¹´365èµ¢ã€‘ç³»ç»Ÿæ—¥æŠ¥
ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M")}

ğŸ“Š è¿è¡Œç»Ÿè®¡ï¼š
- DeepSeek APIè°ƒç”¨ï¼š{status['components']['deepseek']['request_count']}æ¬¡
- å¤„ç†å†…å®¹æ€»æ•°ï¼š{status['components']['processor']['processed']}æ¡
- ç”¨æˆ·åé¦ˆæ€»æ•°ï¼š{status['components']['feedback']['total_feedbacks']}æ¬¡

ğŸ‘¤ ç”¨æˆ·æ´å¯Ÿï¼š
- æ»¡æ„åº¦è¶‹åŠ¿ï¼š{insights.get('satisfaction_trend', 'æ•°æ®ä¸è¶³')}
- åå¥½ç¨³å®šæ€§ï¼š{insights.get('preference_stability', 0.5):.1%}
- æœ€ä½³æ¨é€æ—¶é—´ï¼š{', '.join(insights.get('optimal_times', []))}

ğŸ’¡ æ”¹è¿›å»ºè®®ï¼š
{chr(10).join(f"- {suggestion}" for suggestion in insights.get('improvement_suggestions', ['æš‚æ— å»ºè®®']))}

ğŸ”§ ç³»ç»Ÿå¥åº·ï¼šè¿è¡Œæ­£å¸¸
"""
        
        return report


def main():
    """ä¸»å‡½æ•°"""
    
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸€å¹´365èµ¢ä¿¡æ¯èŒ§æˆ¿ç³»ç»Ÿ")
    parser.add_argument("--workflow", choices=["morning", "noon", "evening"], 
                       help="è¿è¡ŒæŒ‡å®šå·¥ä½œæµ")
    parser.add_argument("--report", action="store_true", 
                       help="ç”Ÿæˆç³»ç»Ÿæ—¥æŠ¥")
    parser.add_argument("--status", action="store_true",
                       help="æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
    parser.add_argument("--test", action="store_true",
                       help="è¿è¡Œæµ‹è¯•")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å·¥ä½œæµ
    try:
        workflow = Year365WinWorkflow()
    except Exception as e:
        print(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ“ä½œ
    if args.workflow:
        print(f"å¼€å§‹è¿è¡Œ{args.workflow}å·¥ä½œæµ...")
        briefing = workflow.run_daily_workflow(args.workflow)
        if briefing:
            print(f"\n{briefing}")
        else:
            print("å·¥ä½œæµæ‰§è¡Œå¤±è´¥")
    
    elif args.report:
        report = workflow.generate_daily_report()
        print(report)
    
    elif args.status:
        status = workflow.get_system_status()
        print(json.dumps(status, ensure_ascii=False, indent=2))
    
    elif args.test:
        print("è¿è¡Œæµ‹è¯•...")
        # æµ‹è¯•å„å·¥ä½œæµ
        for wf_type in ["morning", "noon", "evening"]:
            print(f"\næµ‹è¯•{wf_type}å·¥ä½œæµ:")
            briefing = workflow.run_daily_workflow(wf_type)
            if briefing:
                print(f"ç”Ÿæˆç®€æŠ¥é•¿åº¦ï¼š{len(briefing)}å­—ç¬¦")
            else:
                print("æµ‹è¯•å¤±è´¥")
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()